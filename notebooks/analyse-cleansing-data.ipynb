{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analiza danych: regresja X->Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_data = \"data\" # tu wpisz adres folderu, gdzie zapisałeś dane\n",
    "\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dane treningowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_hdf(os.path.join(folder_data, \"X.h5\"), \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.read_hdf(os.path.join(folder_data, \"Y.h5\"), \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function (funkcja straty / kryterium dopasowania) to R^2 -> max R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(Y, Y_pred):\n",
    "    return metrics.r2_score(Y, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zmienne pomocnicze\n",
    "\n",
    "# Lista nazw predykatorów.\n",
    "PREDICTORS_NAMES = frozenset(X.columns.values)\n",
    "\n",
    "STATISTIC_TEST_NAMES = frozenset([\n",
    "    'Pearson',\n",
    "    'Spearman '    \n",
    "])\n",
    "\n",
    "STATISTIC_TESTS = {\n",
    "    'Pearson': stats.normaltest,\n",
    "    'Shapiro': stats.shapiro\n",
    "}\n",
    "\n",
    "MIN_SIZE_PREDICTORS = 2\n",
    "MAX_SIZE_PREDICTORS = 15\n",
    "\n",
    "# Kombinacje predykatorów o rozmiarze 2.\n",
    "PREDICTOR_COMBINATIONS = list(combinations(PREDICTORS_NAMES, 2))\n",
    "\n",
    "STATISTIC_THRESHOLD = 2000\n",
    "\n",
    "ALPHA = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testy statystyczne sprawdzające czy dany predyktor ma rozkład Gaussa.\n",
    "\n",
    "Testy ,,normalności\" są używane do określenia czy zbiór danych jest dobrze modelowany przez rozkład normalny i obliczenia prawdopodobieństwa normalnego rozkładu zmiennej losowej leżącej u podstaw zbioru danych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretacja testu czy dana zmienna ma rozkład normalny (Gaussa)\n",
    "W każdym teście obliczamy wartość statystyki i p-wartość (prawdopodobieństwo).\n",
    " - Statystyka (`statistic`): Wielkość obliczona przez test, którą można zinterpretować w kontekście testu porównując ją z wartościami krytycznymi z rozkładu statystyki testowej.\n",
    " \n",
    "- p-wartość (`p_value`): interpreter testu, który pozwala weryfikować hipotezę statystyczną, w tym przypadku czy zmienna ma rozkład normalny.\n",
    "\n",
    "Testy zakładają, że próbka została pobrana z rozkładu Gaussa. Technicznie nazywa się to hipotezą zerową lub H0. Wybiera się poziom progowy zwany alfą (`ALPHA`), zwykle jest to 5% (lub 0.05), który jest używany do interpretacji wartości p.\n",
    "\n",
    "W bibliotece SciPy, w implementacji tych testów - p-wartość należy rozpratrywać następująco\n",
    "\n",
    "- p <= alpha: odrzucenie hipotezy H0, rozkład zmiennej nie jest normalny (Gaussa)\n",
    "- p > alpha: nie ma podstaw do odrzucenia hipotezy H0, zmienna ma rozkład normalny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dodałem próg dla wartości statystki, bez tego otrzymywałem jeden rezultat.\n",
    "# Wydaje mi się to podejrzane, dlatego też to zrobiłem. Kilka komórek poniżej\n",
    "# wydrukowuje wykresy dla tych zmiennych (predykatorów).\n",
    "# Dobrym pytanie jest dla taka wartość progu dla statystyki. Analizując dla każdego\n",
    "# predykatu wartośc statystyki stwierdziłem, że taki próg będzie ok - bo wartość statystyk\n",
    "# była bardzo ,,szeroka\".\n",
    "\n",
    "# Funkcje analizujące wyniki normality test.\n",
    "def analyse_pearson_normal_test(entry) -> bool:\n",
    "    statistic = entry['statistic']\n",
    "    p_value = entry['p_value']\n",
    "    return True if (p_value > ALPHA or statistic < STATISTIC_THRESHOLD) else False\n",
    "\n",
    "def analyse_shapiro_normal_test(entry) -> bool:\n",
    "    statistic = entry['statistic']\n",
    "    p_value = entry['p_value']\n",
    "    return True if p_value > ALPHA else False\n",
    "\n",
    "# Klasyfikacja korelacji liniowej Pearsona\n",
    "def classification_correlation(classified_correlations: dict, correlations: dict) -> dict:\n",
    "    '''\n",
    "    classified_correlations -> słownik\n",
    "    correlations -> słownik z korelacjami dwóch zmiennych, gdzie ,,kluczem'' (key) \n",
    "    w tej hash mapie jest string jako konkatenacja nazwy dwóch zmiennych,\n",
    "    wartością (value) jest wartości współczynnika korelacji liniowej.\n",
    "    '''\n",
    "    \n",
    "    for name, value in correlations.items():\n",
    "        if 0 < value < 0.1:\n",
    "            classified_correlations['VERY_WEAK'].append(name)\n",
    "        elif 0.1 <= value < 0.3:\n",
    "            classified_correlations['WEAK'].append(name)\n",
    "        elif 0.3 <= value < 0.5:\n",
    "            classified_correlations['AVERAGE'].append(name)\n",
    "        elif 0.5 <= value < 0.7:\n",
    "            classified_correlations['HIGH'].append(name)\n",
    "        elif 0.7 <= value < 0.9:\n",
    "            classified_correlations['VERY_HIGH'].append(name)\n",
    "        elif 0.1 <= value < 1:\n",
    "            classified_correlations['ALMOST_FULL'].append(name)\n",
    "        elif value == 1:\n",
    "            classified_correlations['PERFECT'].append(name)\n",
    "    \n",
    "    return classified_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic_test = {\n",
    "    'Pearson': [],\n",
    "    'Shapiro': []\n",
    "}\n",
    "\n",
    "# Wykonanie testów czt dany predykator ma rozkład normalny (Gaussa).\n",
    "for predictor_name in PREDICTORS_NAMES:\n",
    "    for statistic_name, test in STATISTIC_TESTS.items():\n",
    "        statistic, p_value = test(X[predictor_name])\n",
    "        item = { 'name': predictor_name, 'statistic': statistic, 'p_value': p_value }\n",
    "        statistic_test[statistic_name].append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtracja testów\n",
    "for statistic_name, tests in statistic_test.items():\n",
    "    statistic_test[statistic_name] = sorted(tests, key=lambda entry: entry['statistic'])\n",
    "    if statistic_name == 'Pearson':\n",
    "        statistic_test[statistic_name] = list(filter(analyse_pearson_normal_test, tests))\n",
    "    elif statistic_name == 'Shapiro':\n",
    "        statistic_test[statistic_name] = list(filter(analyse_shapiro_normal_test, tests))\n",
    "        \n",
    "pearson_tests = statistic_test['Pearson']\n",
    "shapiro_tests = statistic_test['Shapiro']\n",
    "\n",
    "print(f'Pearson normality tests count -> {len(pearson_tests)}')\n",
    "print(f'Shapiro normality tests count -> {len(shapiro_tests)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyodrębniłem wybrane predykatory, które są zbliżone do rozkłady normalnego.\n",
    "selected_predictors = set()\n",
    "for entry in pearson_tests:\n",
    "    selected_predictors.add(entry['name'])\n",
    "    \n",
    "for entry in shapiro_tests:\n",
    "    selected_predictors.add(entry['name'])\n",
    "    \n",
    "print(f\"Selected predictors based on normality test -> \\n {*selected_predictors,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wizualizuje zmienne, dla których test statystyczny określił, że mają\n",
    "# rozkład normalny. (Upewniam się czy nie popełniłem wcześnie błędu w podejściu)\n",
    "for selected_predictor in selected_predictors:\n",
    "    plt.figure()\n",
    "    X[selected_predictor].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obliczam średnią dla każdego predyktora\n",
    "mean_predictors = defaultdict()\n",
    "for predictor_name in PREDICTORS_NAMES:\n",
    "    mean_predictors[f'mean_{predictor_name}'] = X[predictor_name].mean()\n",
    "    \n",
    "# Obliczam korelację liniową Pearsona między dwoma zmiennymi.\n",
    "predictors_correlation = defaultdict()\n",
    "for p1, p2 in PREDICTOR_COMBINATIONS:\n",
    "    predictors_correlation[f'r_{p1}_{p2}'] = abs(stats.pearsonr(X[p1], X[p2])[0])\n",
    "#     predictors_correlation[f'r_{p1}_{p2}'] = np.corrcoef(X[p1], X[p2])[0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Klasyfikacja współczynnika korelacji liniowej Pearsona\n",
    "\n",
    "Niech *r* oznacza wartość korelacji liniowej Pearsona.\n",
    "\n",
    "* r = 0 -> brak zależności\n",
    "*  0  < |r| < 0.1 -> korelacja nikła\n",
    "* 0.1 <= |r| < 0.3 -> korelacja słaba\n",
    "* 0.3 <= |r| < 0.5 -> korelacja przeciętna\n",
    "* 0.5 <= |r| < 0.7 -> korelacja wysoka\n",
    "* 0.7 <= |r| < 0.9 -> korelacja bardzo wysoka\n",
    "* 0.9 <= |r| <  1  -> korelacja prawie pełna\n",
    "* |r| = 1 -> ,,doskonała\" zależność\n",
    "\n",
    "Oczywiście, że wartości korelacji, które wyznaczają brak zależności liniowej nie wykluczają, że zmienne (predykatory) mogą być zależne, ale zależność ta jest krzywoliniowa. Z drugiej strony wysoka wartość korelacji nie oznacza jednoznacznie, że istnieje duża zależność liniowa między zmiennymi (predykatorami). Może to być spowodowane istnieniem innej zmiennej lub zmiennychm, które między tymi predykatorami są silnie skolerowane.\n",
    "\n",
    "Myślę, że jest to punkt odniesienia to zbudowana modelu, wzoru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oceniam korelację między dwoma zmiennymi\n",
    "classified_correlation_predictors = {\n",
    "    'VERY_WEAK': [],\n",
    "    'WEAK': [],\n",
    "    'AVERAGE': [],\n",
    "    'HIGH': [],\n",
    "    'VERY_HIGH': [],\n",
    "    'ALMOST_FULL': [],\n",
    "    'PERFECT': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oceniam korelację między dwoma zmiennymi\n",
    "classified_correlation_predictors = classification_correlation(classified_correlation_predictors, predictors_correlation)\n",
    "\n",
    "for classificator, predictor_names in classified_correlation_predictors.items():\n",
    "    print(f'{classificator} -> {len(predictor_names)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmapa dotycząca korelacji zmiennych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = X.corr()\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korelacja między predykatorem a wartości Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_target_corrlation = defaultdict()\n",
    "for predictor_name in PREDICTORS_NAMES:\n",
    "    predictor_target_corrlation[f'r_{predictor_name}_y'] = np.corrcoef(X[predictor_name], Y)[0, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oceniam korelację między dwoma predykatorem a wartością Y\n",
    "classified_correlation_target_predictors = {\n",
    "    'VERY_WEAK': [],\n",
    "    'WEAK': [],\n",
    "    'AVERAGE': [],\n",
    "    'HIGH': [],\n",
    "    'VERY_HIGH': [],\n",
    "    'ALMOST_FULL': [],\n",
    "    'PERFECT': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oceniam korelację między dwoma zmiennymi\n",
    "classified_correlation_target_predictors = classification_correlation(classified_correlation_target_predictors, predictor_target_corrlation)\n",
    "\n",
    "for classificator, predictor_names in classified_correlation_target_predictors.items():\n",
    "    print(f'{classificator} -> {len(predictor_names)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wyodrębnienie predykatorów z już klasyfikowanymi wartościami korelacji\n",
    "\n",
    "Interesują mnie przede następujące zależności:\n",
    "   * PERFECT\n",
    "   * ALMOST_FULL\n",
    "   * VERY_HIGH\n",
    "   * HIGH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obliczam ilość wystąpień predykatów w powyżej wymienionych.\n",
    "first_statitistic_correlation_predictors = defaultdict(int)\n",
    "second_statitistic_correlation_predictors = defaultdict(int)\n",
    "selected_keys = frozenset(['PERFECT', 'ALMOST_FULL', 'VERY_HIGH', 'HIGH'])\n",
    "for key, items in classified_correlation_predictors.items():\n",
    "    if key not in selected_keys:\n",
    "        continue\n",
    "    \n",
    "    for item in items:\n",
    "        first_pred, second_pred = item.split('_')[1:]\n",
    "        first_statitistic_correlation_predictors[first_pred] += 1\n",
    "        second_statitistic_correlation_predictors[second_pred] += 1\n",
    "\n",
    "# Obliczam średnią wystąpień predykatu w danej klasyfikacji.\n",
    "first_treshold_mean = np.mean(list(first_statitistic_correlation_predictors.values()))\n",
    "second_treshold_mean = np.mean(list(second_statitistic_correlation_predictors.values()))\n",
    "\n",
    "# Wartości wystąpień predykatu powyżej średniej dorzucam do już wyselekcjonowanych\n",
    "# predykatów.\n",
    "for predictor, count in first_statitistic_correlation_predictors.items():\n",
    "    if count > first_treshold_mean:\n",
    "        selected_predictors.update(predictor)\n",
    "\n",
    "for predictor, count in second_statitistic_correlation_predictors.items():\n",
    "    if count > second_treshold_mean:\n",
    "        selected_predictors.update(predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wyodrębnienie predykatorów z obliczeń korelacji z wartością Y (target)\n",
    "\n",
    "Ze wcześniejszych obliczeń wyszło, że są dwie klasyfikacje `VERY_WEAK` i `WEAK`. Co oznacza, że jest poniżej przeciętnej. Wniosek stąd taki, że bierzemy tylko predykatory z ,,szufladki\" `WEAK`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ,,Wyciągam\" predykaty.\n",
    "statitistic_correlation_target_predictors = set()\n",
    "selected_keys = frozenset(['WEAK'])\n",
    "for key, items in classified_correlation_target_predictors.items():\n",
    "    if key not in selected_keys:\n",
    "        continue\n",
    "    \n",
    "    for item in items:\n",
    "        predictor = item.split('_')[1]\n",
    "        statitistic_correlation_target_predictors.add(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyciągam wartość wspólną z dwóch zbiorów predykatów.\n",
    "statitistic_correlation_target_predictors.intersection_update(selected_predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analizując dane, wyciągnąłem predykaty, które wykorzystam do zbudowania modelu.\n",
    "\n",
    "Oto one ->\n",
    "`f1`, `f15`, `f30`, `f45`, `f66`, `f134`, `f198`, `f202`,\n",
    "`f207`, `f208`, `f209`, `f211`, `f212`, `f213`, `f221`, `f259`,\n",
    "`f260`, `f267`, `f268`, `f275`, `f276`, `f280`, `f284`, `f288`,\n",
    "`f289`, `f290`, `f291`, `f292`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTED_PREDICTORS = frozenset(statitistic_correlation_target_predictors)\n",
    "SELECTED_X_DATA = X[SELECTED_PREDICTORS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test , y_train, y_test = train_test_split(SELECTED_X_DATA, Y, test_size=0.3, random_state=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}